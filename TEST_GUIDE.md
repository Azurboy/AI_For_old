# 🧪 测试指南 - 讯飞语音识别

本指南将帮助你测试讯飞语音识别API是否正常工作。

---

## ✅ 已完成配置

讯飞API密钥已经配置到 `backend/.env` 文件：

```bash
XUNFEI_APP_ID=62fed114
XUNFEI_API_KEY=23c852ec7b677eb9b7f28fbfe9527da7
XUNFEI_API_SECRET=Njk5NGU1M2MxMzNiMmNhNjJlNzZjNGVm
```

---

## 🚀 测试方法

### 方法1: Web界面测试（推荐⭐）

这是最真实的测试方式，模拟实际使用场景。

#### Step 1: 启动后端

```bash
cd backend
python3 main.py
```

你应该看到：
```
✅ 数据库已初始化
✅ ChromaDB已就绪
🚀 服务器启动成功！
INFO:     Uvicorn running on http://0.0.0.0:8000
```

#### Step 2: 启动前端

**新开一个终端：**

```bash
cd frontend
npm run dev
```

你应该看到：
```
VITE v5.0.0  ready in xxx ms

➜  Local:   http://localhost:3000/
```

#### Step 3: 浏览器测试

1. 打开浏览器访问 **http://localhost:3000**
2. 点击 **"呼叫小雅"** 按钮
3. 浏览器会请求麦克风权限，点击 **"允许"**
4. 进入通话界面后，**对着麦克风说话**（例如："今天天气真好"）
5. 观察页面下方的状态：
   - "等待您说话" → 正在监听
   - "正在聆听您说话..." → 检测到声音，开始录音
6. 说完后保持**1.5秒静音**，系统会自动停止录音并发送到后端

#### Step 4: 查看后端日志

切换回后端终端，你应该看到类似的日志：

```bash
讯飞STT响应状态: 200
讯飞STT响应: {'code': 0, 'data': {...}}
✅ 识别成功: 今天天气真好
✅ 对话已保存: 今天天气真好...
```

**成功标志：**
- ✅ 看到 "识别成功: XXX"
- ✅ AI有回复（播放语音或显示文本）
- ✅ 对话保存到数据库

---

### 方法2: 命令行测试（快速验证）

如果你只想快速验证API配置是否正确。

#### Step 1: 运行配置检查

```bash
cd backend
python3 test_xunfei_stt.py
```

你应该看到：

```
🔧 检查API配置...
------------------------------------------------------------
✅ XUNFEI_APP_ID: 62fed114
✅ XUNFEI_API_KEY: 23c852ec***
✅ XUNFEI_API_SECRET: Njk5NGU1***
------------------------------------------------------------
```

#### Step 2: 使用音频文件测试（可选）

如果你有一个测试音频文件（.wav, .mp3等）：

```bash
cd backend
python3 test_xunfei_stt.py /path/to/your/audio.wav
```

示例输出：

```
============================================================
🎤 测试讯飞语音识别API
============================================================
📁 音频文件: test.wav
📊 音频大小: 52480 bytes

🔄 正在调用讯飞API...
------------------------------------------------------------
讯飞STT响应状态: 200
讯飞STT响应: {'code': 0, 'data': {...}}
✅ 识别成功: 今天天气真好
------------------------------------------------------------

✨ 识别结果:
   今天天气真好

============================================================
```

---

### 方法3: API直接测试

使用 `curl` 或 Postman 直接测试API端点。

#### 准备音频文件

确保你有一个音频文件（例如 `test.wav`）。

#### 发送请求

```bash
curl -X POST http://localhost:8000/api/chat \
  -F "audio=@test.wav" \
  -v
```

#### 查看响应

响应头中会包含识别结果：

```
< HTTP/1.1 200 OK
< X-AI-Text: 哎呀，您说的真好！...
< X-User-Text: 今天天气真好
< Content-Type: audio/mpeg
```

---

## 🔍 故障排除

### 问题1: "⚠️ 未配置讯飞API，使用模拟数据"

**原因**: 环境变量未正确加载

**解决**:
```bash
# 检查 .env 文件是否存在
ls backend/.env

# 如果不存在，创建它
cd backend
cat > .env << EOF
XUNFEI_APP_ID=62fed114
XUNFEI_API_KEY=23c852ec7b677eb9b7f28fbfe9527da7
XUNFEI_API_SECRET=Njk5NGU1M2MxMzNiMmNhNjJlNzZjNGVm
EOF

# 重启后端
python3 main.py
```

### 问题2: "❌ 讯飞API错误 [10013]: sid is illegal"

**原因**: 鉴权参数错误

**解决**: 
- 检查APPID、APIKey、APISecret是否正确
- 确保没有多余的空格或换行

### 问题3: "❌ 讯飞API错误 [10106]: invalid parameter"

**原因**: 音频格式不支持

**解决**: 
- 前端录制的是WebM格式，需要确保浏览器支持
- 尝试使用Chrome浏览器（兼容性最好）

### 问题4: 麦克风权限被拒绝

**原因**: 浏览器安全策略

**解决**:
- Chrome: 点击地址栏左侧的🔒图标 → 权限 → 麦克风 → 允许
- Safari: 偏好设置 → 网站 → 麦克风 → 允许
- 确保使用 `localhost` 或 `https://`

### 问题5: 识别结果为空

**原因**: 
- 说话声音太小
- 环境噪音太大
- 录音时长太短

**解决**:
- 靠近麦克风说话
- 说话时间至少1秒
- 说完后等待1.5秒再动（让VAD检测静音）

---

## 📊 成功标志

### 后端日志（正常）

```
讯飞STT响应状态: 200
讯飞STT响应: {'code': 0, 'data': {'result': {...}}}
✅ 识别成功: 今天天气真好
✅ 对话已保存: 今天天气真好...
```

### 前端界面（正常）

1. ✅ 点击"呼叫"能进入通话界面
2. ✅ 看到"等待您说话"提示
3. ✅ 说话时看到"正在聆听您说话..."和动画
4. ✅ 静音后自动停止录音
5. ✅ 收到AI的回复（文本或语音）

### 仪表盘（正常）

访问 http://localhost:8080，点击"刷新数据"：

1. ✅ 对话次数增加
2. ✅ 看到对话内容（用户说的话）
3. ✅ 人生纪要中包含对话信息

---

## 🎯 测试场景

### 场景1: 普通话测试

说：**"今天天气真好"**

期望：准确识别

### 场景2: 短句测试

说：**"你好"**

期望：准确识别（至少说0.5秒以上）

### 场景3: 长句测试

说：**"我今天早上吃了一碗面条，然后出去散步了"**

期望：准确识别完整句子

### 场景4: 方言测试（可选）

如果你会说方言，可以尝试用方言说话，测试识别效果。

需要修改 `backend/ai_services.py` 中的accent参数：

```python
"accent": "mandarin",  # 改为 "cantonese"（粤语）, "lmz"（四川话）等
```

---

## 📈 性能指标

| 指标 | 预期值 |
|------|--------|
| 识别延迟 | 1-3秒 |
| 识别准确率 | >95%（普通话） |
| 支持音频时长 | <60秒 |
| 音频格式 | WebM, WAV, MP3 |

---

## 🎉 测试完成检查清单

完成以下所有项，说明集成成功：

- [ ] 后端启动无错误
- [ ] 前端能访问（http://localhost:3000）
- [ ] 能进入通话界面
- [ ] 麦克风权限已授权
- [ ] 说话时看到"正在聆听"提示
- [ ] 后端日志显示"识别成功"
- [ ] AI有回复
- [ ] 仪表盘能看到对话记录

全部打钩？**恭喜！讯飞语音识别集成成功！** 🎊

---

## 💡 下一步

测试成功后，你可以：

1. **优化识别效果**:
   - 调整VAD静音检测时长（`VoiceActivityDetector.jsx`中的`SILENCE_DURATION`）
   - 调整音量阈值（`VOICE_THRESHOLD`）

2. **添加方言支持**:
   - 修改`accent`参数
   - 测试不同方言的识别效果

3. **集成其他AI服务**:
   - 配置Gemini API（更智能的对话）
   - 配置ElevenLabs TTS（更自然的语音）

---

## 📞 获取帮助

如果遇到问题：

1. 查看后端日志（详细错误信息）
2. 查看浏览器控制台（前端错误）
3. 检查 `.env` 配置是否正确
4. 参考本文档的"故障排除"部分

---

**祝你测试成功！** 🚀


