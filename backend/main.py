"""
ä¸»APIæœåŠ¡å™¨ - FastAPI
"""
# é¦–å…ˆåŠ è½½ç¯å¢ƒå˜é‡
from dotenv import load_dotenv
load_dotenv()

from fastapi import FastAPI, UploadFile, File, BackgroundTasks, Depends
from fastapi.middleware.cors import CORSMiddleware
from fastapi.responses import Response, JSONResponse
from sqlalchemy.orm import Session
from datetime import datetime
from urllib.parse import quote
import uuid

from database import init_db, get_db, ChatHistory
from vector_store import vector_store
from ai_services import ai_services

# åˆå§‹åŒ–FastAPI
app = FastAPI(title="YuKeSong API", version="1.0.0")

# CORSé…ç½®ï¼ˆå…è®¸å‰ç«¯è®¿é—®ï¼‰
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # MVPé˜¶æ®µå…è®¸æ‰€æœ‰æ¥æº
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# å¯åŠ¨æ—¶åˆå§‹åŒ–æ•°æ®åº“
@app.on_event("startup")
async def startup_event():
    init_db()
    print("âœ… æ•°æ®åº“å·²åˆå§‹åŒ–")
    print("âœ… ChromaDBå·²å°±ç»ª")
    print("ğŸš€ æœåŠ¡å™¨å¯åŠ¨æˆåŠŸï¼")


@app.get("/")
async def root():
    """å¥åº·æ£€æŸ¥"""
    return {
        "status": "ok",
        "message": "YuKeSong API is running",
        "version": "1.0.0",
        "siliconflow_configured": bool(ai_services.siliconflow_api_key)
    }


@app.get("/api/config")
async def check_config():
    """æ£€æŸ¥APIé…ç½®çŠ¶æ€"""
    return {
        "siliconflow": {
            "configured": bool(ai_services.siliconflow_api_key),
            "api_key_prefix": ai_services.siliconflow_api_key[:10] + "..." if ai_services.siliconflow_api_key else "æœªé…ç½®",
            "services": {
                "stt": "TeleAI/TeleSpeechASR",
                "llm": "Qwen/Qwen2.5-7B-Instruct"
            }
        },
        "elevenlabs": {
            "configured": bool(ai_services.elevenlabs_api_key)
        }
    }


@app.post("/api/chat")
async def chat_endpoint(
    audio: UploadFile = File(...),
    background_tasks: BackgroundTasks = BackgroundTasks(),
    db: Session = Depends(get_db)
):
    """
    æ ¸å¿ƒäº¤äº’ç«¯ç‚¹ (F-007)
    
    æµç¨‹ï¼š
    1. STT: è®¯é£è¯­éŸ³è¯†åˆ«
    2. Context: æ£€ç´¢ç›¸å…³è®°å¿†
    3. LLM: Geminiç”Ÿæˆå›å¤
    4. TTS: ElevenLabsç”Ÿæˆè¯­éŸ³
    5. Save: åå°ä¿å­˜åˆ°æ•°æ®åº“å’Œå‘é‡åº“
    """
    try:
        # è¯»å–éŸ³é¢‘æ•°æ®
        audio_data = await audio.read()
        
        # Step 1: STT - è¯­éŸ³è½¬æ–‡å­—
        user_text = await ai_services.speech_to_text(audio_data)
        
        if not user_text or user_text == "è¯­éŸ³è¯†åˆ«å¤±è´¥ï¼Œè¯·é‡è¯•":
            return JSONResponse(
                status_code=400,
                content={"error": "è¯­éŸ³è¯†åˆ«å¤±è´¥"}
            )
        
        # Step 2: æ£€ç´¢ç›¸å…³è®°å¿†
        relevant_memories = vector_store.query_relevant_memories(user_text, n_results=3)
        
        # è·å–æœ€è¿‘å¯¹è¯å†å²
        recent_history = db.query(ChatHistory).order_by(
            ChatHistory.timestamp.desc()
        ).limit(5).all()
        
        history_list = [
            {"user_text": h.user_text, "ai_text": h.ai_text}
            for h in reversed(recent_history)
        ]
        
        # Step 3: LLM - ç”ŸæˆAIå›å¤
        ai_text = await ai_services.generate_response(
            user_text=user_text,
            conversation_history=history_list,
            relevant_memories=relevant_memories
        )
        
        # Step 4: TTS - ç”Ÿæˆè¯­éŸ³
        audio_response = await ai_services.text_to_speech(ai_text)
        
        # Step 5: åå°ä¿å­˜ï¼ˆä¸é˜»å¡å“åº”ï¼‰
        background_tasks.add_task(
            save_conversation,
            db=db,
            user_text=user_text,
            ai_text=ai_text
        )
        
        # è¿”å›éŸ³é¢‘å’Œæ–‡æœ¬ï¼ˆå¯¹ä¸­æ–‡è¿›è¡ŒURLç¼–ç ä»¥æ”¯æŒHTTP headerï¼‰
        from urllib.parse import quote
        return Response(
            content=audio_response,
            media_type="audio/mpeg",
            headers={
                "X-AI-Text": quote(ai_text),  # URLç¼–ç ä¸­æ–‡
                "X-User-Text": quote(user_text)
            }
        )
        
    except Exception as e:
        print(f"Chat Error: {e}")
        return JSONResponse(
            status_code=500,
            content={"error": str(e)}
        )


def save_conversation(db: Session, user_text: str, ai_text: str):
    """åå°ä»»åŠ¡ï¼šä¿å­˜å¯¹è¯åˆ°æ•°æ®åº“å’Œå‘é‡åº“"""
    try:
        # ä¿å­˜åˆ°SQLite
        chat = ChatHistory(
            session_id="demo_elder",
            user_text=user_text,
            ai_text=ai_text,
            timestamp=datetime.utcnow()
        )
        db.add(chat)
        db.commit()
        
        # ä¿å­˜åˆ°ChromaDB
        conversation_id = f"conv_{uuid.uuid4().hex[:8]}"
        vector_store.add_conversation(conversation_id, user_text, ai_text)
        
        print(f"âœ… å¯¹è¯å·²ä¿å­˜: {user_text[:20]}...")
        
    except Exception as e:
        print(f"ä¿å­˜å¤±è´¥: {e}")
        db.rollback()


@app.get("/api/generate_biography")
async def generate_biography(db: Session = Depends(get_db)):
    """
    æ¼”ç¤ºç«¯ç‚¹ (F-008)
    
    ç”Ÿæˆï¼š
    1. è€äººçš„"äººç”Ÿçºªè¦"ï¼ˆMarkdownï¼‰
    2. è®¤çŸ¥å¥åº·è¯„ä¼°ï¼ˆJSONï¼‰
    """
    try:
        # è·å–æ‰€æœ‰å¯¹è¯è®°å½•
        all_conversations = db.query(ChatHistory).order_by(
            ChatHistory.timestamp.asc()
        ).all()
        
        if not all_conversations:
            return {
                "biography": "## æš‚æ— å¯¹è¯è®°å½•\n\nè¯·å…ˆä¸è€äººè¿›è¡Œå¯¹è¯ã€‚",
                "cognitive_assessment": {
                    "overall_risk": "æœªè¯„ä¼°",
                    "memory_score": 0,
                    "time_orientation": 0,
                    "language_fluency": 0,
                    "concerns": ["æš‚æ— æ•°æ®"]
                },
                "total_conversations": 0
            }
        
        # è°ƒç”¨AIç”Ÿæˆä¼ è®°å’Œè¯„ä¼°
        result = await ai_services.generate_biography(all_conversations)
        
        return {
            **result,
            "total_conversations": len(all_conversations),
            "first_conversation": all_conversations[0].timestamp.isoformat(),
            "last_conversation": all_conversations[-1].timestamp.isoformat()
        }
        
    except Exception as e:
        print(f"Biography Error: {e}")
        return JSONResponse(
            status_code=500,
            content={"error": str(e)}
        )


@app.get("/api/conversations")
async def get_conversations(limit: int = 50, db: Session = Depends(get_db)):
    """è·å–å¯¹è¯å†å²ï¼ˆè°ƒè¯•ç”¨ï¼‰"""
    conversations = db.query(ChatHistory).order_by(
        ChatHistory.timestamp.desc()
    ).limit(limit).all()
    
    return {
        "total": len(conversations),
        "conversations": [
            {
                "id": conv.id,
                "user_text": conv.user_text,
                "ai_text": conv.ai_text,
                "timestamp": conv.timestamp.isoformat()
            }
            for conv in conversations
        ]
    }


@app.get("/api/dashboard/insights")
async def get_dashboard_insights(db: Session = Depends(get_db)):
    """
    ä»ªè¡¨ç›˜ç«¯ç‚¹ - å¯¹è¯æ´å¯Ÿåˆ†æ
    
    è¿”å›ï¼š
    1. å¯¹è¯æ€»ç»“
    2. æƒ…æ„Ÿåˆ†æï¼ˆç”¨æˆ·æƒ…ç»ªã€éœ€æ±‚ï¼‰
    3. è®¤çŸ¥èƒ½åŠ›è¯„ä¼°ï¼ˆè®°å¿†ã€æ—¶é—´å®šå‘ã€è¯­è¨€èƒ½åŠ›ï¼‰
    4. å…³é”®ä¿¡æ¯æå–
    """
    try:
        # è·å–æ‰€æœ‰å¯¹è¯è®°å½•
        all_conversations = db.query(ChatHistory).order_by(
            ChatHistory.timestamp.desc()
        ).all()
        
        if not all_conversations:
            return {
                "summary": "æš‚æ— å¯¹è¯æ•°æ®",
                "total_conversations": 0,
                "emotion_analysis": {},
                "cognitive_assessment": {},
                "key_insights": []
            }
        
        # è°ƒç”¨AIè¿›è¡Œæ·±åº¦åˆ†æ
        insights = await ai_services.generate_dashboard_insights(all_conversations)
        
        # æ·»åŠ ç»Ÿè®¡ä¿¡æ¯
        insights["statistics"] = {
            "total_conversations": len(all_conversations),
            "first_conversation": all_conversations[-1].timestamp.isoformat(),
            "last_conversation": all_conversations[0].timestamp.isoformat(),
            "avg_user_text_length": sum(len(c.user_text) for c in all_conversations) / len(all_conversations),
            "recent_conversations": [
                {
                    "user": c.user_text,
                    "ai": c.ai_text,
                    "time": c.timestamp.isoformat()
                }
                for c in all_conversations[:5]
            ]
        }
        
        return insights
        
    except Exception as e:
        print(f"Dashboard Insights Error: {e}")
        import traceback
        traceback.print_exc()
        return JSONResponse(
            status_code=500,
            content={"error": str(e)}
        )


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(
        "main:app",
        host="0.0.0.0",
        port=8000,
        reload=True
    )

